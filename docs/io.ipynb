{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe88076",
   "metadata": {},
   "source": [
    "# Reading/Writing a ðŸŒˆ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84525812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromatic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e591aced",
   "metadata": {},
   "source": [
    "## Reading Files\n",
    "\n",
    "One key goal of `chromatic` is to make it easy to load spectroscopic light curves from a variety of different file formats, so that the outputs from multiple different pipelines can be standardized into objects that can be direcly compared to one another. We hope to provide an straightforward way to check one analysis vs another as quickly as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a5979",
   "metadata": {},
   "source": [
    "### Download Example Inputs\n",
    "\n",
    "If you want to test out any of these readers, you'll need data files in each format to test on. You can download some example datasets from [this link](https://www.dropbox.com/s/es5drnp6ufkz8wv/example-datasets.zip?dl=0). Simply extract that `.zip` file into the directory from which you'll be running this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5027d",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow files (`*.rainbow.npy`)\n",
    "\n",
    "The `chromatic` toolkit saves files in its own default format, which can then be shared and loaded back in. These files directly encode the core dictionaries in binary files, so they load and save quickly. They have the extension `.rainbow.npy`. These files can be written (see below) from any `Rainbow` object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow_chromatic = Rainbow('example-datasets/chromatic/simulated.rainbow.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6439d9d",
   "metadata": {},
   "source": [
    "The `Rainbow` reader will try to guess the format of the file from the filepath. If that doesn't work for some reason, in this case you can feed in the keyword `format='rainbow_npy'`, to require the use of the `from_rainbow_npy` reader needed for these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc80d2f",
   "metadata": {},
   "source": [
    "### generic text files (`*.txt`, `*.csv`)\n",
    "\n",
    "Text files are slower to read or write, but everyone can make them! This reader will try to load one giant text file in which light curves for all wavelengths are stacked on top of each other or spectra for all times are stacked on top of each other. The text file should at least have columns that look like:\n",
    "- `wavelength` for wavelength in microns\n",
    "- `time` for time in days (preferably BJD$_{\\rm TDB}$)\n",
    "- `flux` for flux in any units\n",
    "- `uncertainty` for flux uncertainties in the same units as `flux`\n",
    "Additional columns will also be read, and they will be stored in the `.fluxlike` core dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow_chromatic = Rainbow('example-datasets/chromatic/simulated.rainbow.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262085e9",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='text'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7ffcf",
   "metadata": {},
   "source": [
    "### STScI `jwst` pipeline outputs (`x1dints.fits`)\n",
    "\n",
    "The `jwst` pipeline developed at the Space Telescope Science Institute will produce extract 1D stellar spectra for time-series observations with the James Webb Space Telescope. Details about the pipeline itself are available [here](https://jwst-pipeline.readthedocs.io/en/latest/). \n",
    "\n",
    "These files typically end with the `_x1dints.fits` suffix. Each file contains a number of individual \"integrations\" (= time points). Because the datasets can get large, sometimes a particular observation might be split into multiple segments, each with its own file. As such, the reader for these files is designed to handle either a single file or a path with a `*` in it that points to a group of files from an observation that's been split into segments.\n",
    "\n",
    "This reader has been tested on all of the `x1dints` files produced as Stage 2 Data Products in the simulated datasets available [here](https://app.box.com/folder/154382715453?s=tj1jnivn9ekiyhecl5up7mkg8xrd1htl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2074d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow_stsci = Rainbow('example-datasets/stsci/*_x1dints.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82f7ee",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='x1dints'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7937a802",
   "metadata": {},
   "source": [
    "### `eureka` pipeline outputs (`S3_*_Table_Save.txt`)\n",
    "\n",
    "The `eureka` pipeline is one of many community tools being designed to extract spectra from JWST data. Details about the pipeline itself are available [here](https://github.com/kevin218/Eureka). \n",
    "\n",
    "These files typically have names that look something like `S3_*_Table_Save.txt`, and they contain fluxes as a function of wavelength and time, stored as an astropy `ecsv` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd781dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rainbow_eureka = Rainbow('example-datasets/eureka/S3_wasp43b_Table_Save.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6474155",
   "metadata": {},
   "source": [
    "If the file-format guess fails, you can feed in the keyword `format='eureka'` to tell the reader to expect one of these files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc92fee3",
   "metadata": {},
   "source": [
    "## Writing Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52df8b8",
   "metadata": {},
   "source": [
    "### `chromatic` rainbow files (`*.rainbow.npy`)\n",
    "\n",
    "The default file format for saving files encodes the core dictionaries in binary files, using the extension `.rainbow.npy`. This is a file that can be read directly back into `chromatic`. (Indeed, the commands below created the file that we read above.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330b254",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated = SimulatedRainbow().inject_transit()\n",
    "simulated.save('example-datasets/chromatic/simulated.rainbow.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377be1bc",
   "metadata": {},
   "source": [
    "### generic text files (`*.txt`, `*.csv`)\n",
    "\n",
    "Text files provide a more generally readable file format, even though they may be slower to read or write. This writer will create one giant text file that stacks the light curves for all wavelengths on top of each other (if the `group_by='wavelength'` keyword is set) or the spectra for all times on top of each other (if the `group_by='time'` keyword is set). The resulting text file should at least have columns that look like:\n",
    "- `wavelength` for wavelength in microns\n",
    "- `time` for time in days (preferably BJD$_{\\rm TDB}$)\n",
    "- `flux` for flux in any units\n",
    "- `uncertainty` for flux uncertainties in the same units as `flux`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eece938",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulated.save('example-datasets/chromatic/simulated.rainbow.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b310df9",
   "metadata": {},
   "source": [
    "## Create your Own!\n",
    "\n",
    "Naturally, you might want to add new readers to make use of the outputs from other pipelines or new writers to feed into various light curve analyses. To facilitate this, templates are available with human-friendly instructions for how to add a new reader or writer. If you want to try to incorporate a new reader or writer, please:\n",
    "1. Install in development mode (see the [installation instructions](../installation))\n",
    "2. Navigate to `chromatic/rainbows/[readers|writers]/template.py`.\n",
    "3. Follow the instructions.\n",
    "\n",
    "Good luck! If you add something, please consider submitting a Pull Request to share it with the world!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
